{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taeseon-Baek/AI_Project/blob/main/AI_teamproject_developed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI Team Project - Team 4"
      ],
      "metadata": {
        "id": "8vp3DAM6JFFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Submission date: **2021/12/11 Tue**"
      ],
      "metadata": {
        "id": "AIv5tj5WJWzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Introduction\n",
        "\n",
        "With the Internet usage rate exceeding 91%, Internet access has become an essential part of life. The diffusion of computer networks has brought convenience to our lives. But, at the same time, it has created many network security problems. Network security problems refer to illegal information leakage, service obstruction, and system vulnerability through various protocols or networks. For system security, the role of an intrusion detection system is becoming more important. So far, many machine learning algorithms have been applied for intrusion detection systems. However, they require numerous preprocessing processes for finding useful information and data patterns. So, various deep learning-based algorithms such as MLP and CNN started to appear. Among them, a model that combines CNN and LSTM that extracts spatial and temporal information of network traffic is known to have better performance than single CNN or single LSTM models. Therefore, we will apply this CNN-LSTM model with some modifications for resolving class imbalance to the given network intrusion detection problem.\n",
        "\n"
      ],
      "metadata": {
        "id": "hBv0bjY_KnIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data\n",
        "\n",
        "Since 1999, KDD-99 dataset  has been the most widely used data set for the evaluation of traffic classification methods. The KDD-99 dataset was provided which consists of a wide variety of intrusions simulated in a military network environment. It created an environment to acquire raw TCP/IP dump data for a network by simulating a typical US Air Force. A connection is a sequence of TCP packets starting and ending at some time duration between which data flows to and from a source IP address to a target IP address under some well-defined protocol. Also, each connection is labelled as either normal or as an attack with exactly one specific attack type. The attacks in KDD-99 data set fall in four categories as following:\n",
        "1) Denial of Service Attack (DOS): is an attack in which the attacker makes some computing or memory resource too busy or too full to handle legitimate requests, or denies legitimate users access to a machine.\n",
        "2) User to Root Attack (U2R): is a class of exploit in which the attacker starts out with access to a normal user account on the system (perhaps gained by sniffing passwords, a dictionary attack, or social engineering) and is able to exploit some vulnerability to gain root access to the system.\n",
        "3) Remote to Local Attack (R2L): occurs when an attacker who has the ability to send packets to a machine over a network but who does not have an account on that machine exploits some vulnerability to gain local access as a user of that machine.\n",
        "4) Probing attack: is an attempt to gather information about a network of computers for the apparent purpose of circumventing its security controls. \n",
        "Attack category\tData set\n",
        "\tKDDCup 99\n",
        "Normal\t972780(19.86%)\n",
        "DOS\t3883370(79.28%)\n",
        "Probe\t41102(0.84%)\n",
        "R2L\t1126(0.02%)\n",
        "U2R\t52\n",
        "Table 1. Detailed Composition of KDD Cup99\n",
        "For each TCP/IP connection, 41 quantitative and qualitative features are obtained from normal and attack data (3 qualitative and 38 quantitative features).\n",
        "This data can be classified into normal and 4 attack types, a total of 5 classes.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "For each TCP/IP connection, 41 quantitative and qualitative features are obtained from normal and attack data (3 qualitative and 38 quantitative features).\n",
        "This data can be classified into normal and 4 attack types, a total of 5 classes.\n"
      ],
      "metadata": {
        "id": "5nsS6w8qXHZ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WhUbuvq4ct2",
        "outputId": "b8d5abd5-a9f3-4024-f843-b36f4aef35f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "va3Qr5bO4crc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "columns = ['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','label']\n",
        "data = pd.read_csv('/content/gdrive/MyDrive/Colab_Notebooks/kddcup.data',names=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "--Pd1i674cii"
      },
      "outputs": [],
      "source": [
        "change_value_dict = {'back.':'dos','buffer_overflow.':'u2r','ftp_write.':'r2l','guess_passwd.':'r2l','imap.':'r2l','ipsweep.':'probe','land.':'dos','loadmodule.':'u2r','multihop.':'r2l','neptune.':'dos','nmap.':'probe','perl.':'u2r','phf.':'r2l','pod.':'dos','portsweep.':'probe','rootkit.':'u2r','satan.':'probe','smurf.':'dos','spy.':'r2l','teardrop.':'dos','warezclient.':'r2l','warezmaster.':'r2l','normal.':'normal'}\n",
        "data = data.replace({'label':change_value_dict})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YIyPCfKp4cNR"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
        "#from keras.utils import np_utils\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "import numpy\n",
        "import h5py\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "from sklearn.metrics import plot_confusion_matrix, precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import nan\n",
        "import datetime\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import sqlalchemy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BJIJhXsK5jlg"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "LE = LabelEncoder()\n",
        "data['label'] = LE.fit_transform(data['label']) \n",
        "LE = LabelEncoder()\n",
        "data['protocol_type'] = LE.fit_transform(data['protocol_type'])\n",
        "LE = LabelEncoder()\n",
        "data['service'] = LE.fit_transform(data['service']) \n",
        "LE = LabelEncoder()\n",
        "data['flag'] = LE.fit_transform(data['flag']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8VIEHfDNZJ2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "985223e1-84b6-48fc-f6db-2538c8f4d376"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>root_shell</th>\n",
              "      <th>su_attempted</th>\n",
              "      <th>num_root</th>\n",
              "      <th>num_file_creations</th>\n",
              "      <th>num_shells</th>\n",
              "      <th>num_access_files</th>\n",
              "      <th>num_outbound_cmds</th>\n",
              "      <th>is_host_login</th>\n",
              "      <th>is_guest_login</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>215</td>\n",
              "      <td>45076</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>162</td>\n",
              "      <td>4528</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>236</td>\n",
              "      <td>1228</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>233</td>\n",
              "      <td>2032</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>239</td>\n",
              "      <td>486</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4898426</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>212</td>\n",
              "      <td>2288</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16</td>\n",
              "      <td>3</td>\n",
              "      <td>255</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4898427</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>219</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>4</td>\n",
              "      <td>255</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4898428</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>218</td>\n",
              "      <td>3610</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>5</td>\n",
              "      <td>255</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4898429</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>219</td>\n",
              "      <td>1234</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>6</td>\n",
              "      <td>255</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4898430</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>219</td>\n",
              "      <td>1098</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7</td>\n",
              "      <td>255</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4898431 rows × 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         duration  protocol_type  ...  dst_host_srv_rerror_rate  label\n",
              "0               0              1  ...                       0.0      1\n",
              "1               0              1  ...                       0.0      1\n",
              "2               0              1  ...                       0.0      1\n",
              "3               0              1  ...                       0.0      1\n",
              "4               0              1  ...                       0.0      1\n",
              "...           ...            ...  ...                       ...    ...\n",
              "4898426         0              1  ...                       0.0      1\n",
              "4898427         0              1  ...                       0.0      1\n",
              "4898428         0              1  ...                       0.0      1\n",
              "4898429         0              1  ...                       0.0      1\n",
              "4898430         0              1  ...                       0.0      1\n",
              "\n",
              "[4898431 rows x 42 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# train set과 test set으로 분리\n",
        "x, x_test, y, testY = train_test_split(data.iloc[:,:-1],data.iloc[:,-1], test_size=0.1, random_state=10) #9:1 비율\n",
        "\n",
        "# train set을 test set과 validation set으로 분리\n",
        "X, T, Y, C = train_test_split(x,y, test_size=0.2, random_state=10) #8:2 비율\n",
        "\n",
        "\n",
        "#Normalize\n",
        "scaler = Normalizer().fit(X)\n",
        "trainX = scaler.transform(X)\n",
        "\n",
        "scaler = Normalizer().fit(T)\n",
        "testT = scaler.transform(T)\n",
        "\n",
        "y_train = np.array(Y)\n",
        "y_valid = np.array(C)\n",
        "\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
        "X_valid = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n"
      ],
      "metadata": {
        "id": "0VXunZQLSaG2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TCNK3eYs5mCw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "54b30756-51e2-4a24-87ff-03a160d8bc5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    79.261946\n",
            "1    19.873378\n",
            "2     0.840944\n",
            "3     0.022683\n",
            "4     0.001049\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "count_classes = pd.value_counts(y_train, sort = True,normalize=True).sort_index()\n",
        "print(count_classes*100)\n",
        "# 클래스별 데이터 분포 확인\n",
        "count_classes.plot(kind = 'bar')\n",
        "plt.title(\"class histogram\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "focUbW8_5j7v"
      },
      "outputs": [],
      "source": [
        "# 0. base model (reference 참고해서 CNN_LSTM 모델 구현)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "HemQnMhf5kP0",
        "outputId": "3f7f957d-2a2f-4b5a-bc33-cf42bc2c0a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_LSTM_base.hdf5 파일이 존재하지 않습니다. 새로운 모델을 학습합니다.\n",
            "Epoch 1/3\n",
            "   703/110215 [..............................] - ETA: 22:06 - loss: 0.0930 - accuracy: 0.9718"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a947a7f2da4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoint_2-{epoch:02d}.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#모델 성능에 향상이 있을 때마다 모델 기록\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mcsv_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/cnntrainanalysis.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#log 기록\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Colab_Notebooks/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#학습이 완료된 모델 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 이미 존재하는 모델(model_name)을 불러오는 것인지 새로 학습하는 것인지\n",
        "#\n",
        "#\n",
        "model_name = 'CNN_LSTM_base'\n",
        "filelist = os.listdir(os.getcwd())\n",
        "\n",
        "\n",
        "# 불러오는 경우\n",
        "if (model_name+\".hdf5\") in filelist:\n",
        "    print(model_name+\".hdf5 파일이 존재합니다. 가중치를 불러옵니다.\")\n",
        "\n",
        "    cnn = Sequential()\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "    cnn.add(LSTM(64))\n",
        "    cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "    cnn.load_weights(model_name+\".hdf5\")\n",
        "else:\n",
        "    # 새로운 모델을 학습하려는 경우\n",
        "    print(model_name+\".hdf5 파일이 존재하지 않습니다. 새로운 모델을 학습합니다.\")\n",
        "\n",
        "    ############################################# 모델학습 #############################################\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    '''\n",
        "    #Class Weight 계산\n",
        "    from sklearn.utils import class_weight\n",
        "    class_weight = class_weight.compute_class_weight('balanced',np.unique(Y),Y)\n",
        "    class_weight = dict(zip(np.unique(Y), class_weight))\n",
        "    '''\n",
        "\n",
        "    lstm_output_size = 64\n",
        "\n",
        "    # 모델 학습 시작\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    cnn = Sequential()\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "    cnn.add(LSTM(lstm_output_size))\n",
        "    cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "    # define optimizer and objective, compile cnn\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "    # train\n",
        "    checkpointer = callbacks.ModelCheckpoint(filepath='checkpoint_2-{epoch:02d}.hdf5', verbose=1, save_best_only=True, monitor='val_acc',mode='max') #모델 성능에 향상이 있을 때마다 모델 기록\n",
        "    csv_logger = CSVLogger(os.getcwd()+'/cnntrainanalysis.csv',separator=',', append=False) #log 기록\n",
        "    history = cnn.fit(X_train, y_train, epochs=10,validation_data=(X_valid, y_valid),callbacks=[checkpointer,csv_logger])\n",
        "    cnn.save(\"/content/gdrive/MyDrive/Colab_Notebooks/\"+model_name+\".hdf5\") #학습이 완료된 모델 저장\n",
        "\n",
        "\n",
        "    print('\\nAccuracy: {:.4f}'.format(cnn.evaluate(X_valid, y_valid)[1])) #validation set으로 예측 성능 평가\n",
        "\n",
        "    \n",
        "    #loss graph\n",
        "\n",
        "    y_vloss = history.history['val_loss']\n",
        "    y_loss = history.history['loss']\n",
        "\n",
        "    x_len = np.arange(len(y_loss))\n",
        "    plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "    plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid()\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "########################################### 모델 성능 평가(Evaluation) #####################################\n",
        "\n",
        "#Normalize\n",
        "scaler = Normalizer().fit(x_test)\n",
        "testX = scaler.transform(x_test)\n",
        "\n",
        "y_test = np.array(testY)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_test = np.reshape(testX, (testX.shape[0],testX.shape[1],1))\n",
        "\n",
        "\n",
        "# Test 결과\n",
        "\n",
        "# define optimizer and objective, compile cnn\n",
        "opt = Adam(learning_rate=0.01)\n",
        "cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "y_pred=cnn.predict(X_test) \n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "\n",
        "#np.savetxt('expected.txt', y_test, fmt='%01d')\n",
        "#np.savetxt('predicted.txt', y_pred, fmt='%01d')\n",
        "\n",
        "loss, accuracy = cnn.evaluate(X_test, y_test) #정답 set과 모델이 예측한 값을 비교하여 성능 측정\n",
        "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
        "print()\n",
        "print(metrics.classification_report(y_test, y_pred, digits=5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(y_test, y_pred, digits=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZFRyTA8njc6",
        "outputId": "9e7374ed-063f-4074-afdf-d209e0c7dac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99194   0.99826   0.99509    388264\n",
            "           1    0.97495   0.99378   0.98427     97226\n",
            "           2    0.00000   0.00000   0.00000      4235\n",
            "           3    0.00000   0.00000   0.00000       116\n",
            "           4    0.00000   0.00000   0.00000         3\n",
            "\n",
            "    accuracy                        0.98850    489844\n",
            "   macro avg    0.39338   0.39841   0.39587    489844\n",
            "weighted avg    0.97975   0.98850   0.98410    489844\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# ROC & AUC\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(5):\n",
        "    fpr[i], tpr[i], _ = roc_curve(testY[:, i], y_pred_1[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot of a ROC curve for a specific class\n",
        "plt.figure(figsize=(15, 5))\n",
        "for idx, i in enumerate(range(n_classes)):\n",
        "    plt.subplot(131+idx)\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Class %0.0f' % idx)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "SUUrpc-HXT1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "80ce73ca-a482-4a33-f061-4630e653813c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1aa7ae2aaed8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    919\u001b[0m             )\n\u001b[1;32m    920\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"key of type tuple not found and not a MultiIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(pred,y_test,average=\"weighted\"))"
      ],
      "metadata": {
        "id": "SXgdkm3eXTno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xtVMKkXHrLB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNjx72GJ5mYg"
      },
      "outputs": [],
      "source": [
        "# 1. 하이퍼파라미터 튜닝, 구조 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O56DVYxt2jJ9"
      },
      "outputs": [],
      "source": [
        "#하이퍼파라미터 튜닝(learning_rate을 0.001로), Dropout layer 추가\n",
        "cnn = Sequential()\n",
        "cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "cnn.add(LSTM(lstm_output_size))\n",
        "cnn.add(Dropout(0.1))\n",
        "cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "# define optimizer and objective, compile cnn\n",
        "opt = Adam(learning_rate=0.001)\n",
        "cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhvRp4gE2FEu"
      },
      "outputs": [],
      "source": [
        "# 2. Solving Class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-1. Class Weight(Weight Balancing)"
      ],
      "metadata": {
        "id": "INgWWlLmNWz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fKAnR1P-RcsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad19a129-be86-45db-80b3-047344958ca0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.2523148868854936,\n",
              " 1: 1.0064956902013293,\n",
              " 2: 23.835997945446188,\n",
              " 3: 870.4021717670287,\n",
              " 4: 20039.03181818182}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Class Weight 계산\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y),y=y)\n",
        "class_weight = dict(zip(np.unique(Y), class_weight))\n",
        "class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFelsXQZvct4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8ca871-fc40-40db-bc96-3a62a13e39ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_LSTM_class_weight.hdf5 파일이 존재하지 않습니다. 새로운 모델을 학습합니다.\n",
            "Epoch 1/10\n",
            "110214/110215 [============================>.] - ETA: 0s - loss: 1.1328 - accuracy: 0.9031"
          ]
        }
      ],
      "source": [
        "# 이미 존재하는 모델(model_name)을 불러오는 것인지 새로 학습하는 것인지\n",
        "#\n",
        "#\n",
        "model_name = 'CNN_LSTM_class_weight'\n",
        "filelist = os.listdir(os.getcwd())\n",
        "\n",
        "\n",
        "# 불러오는 경우\n",
        "if (model_name+\".hdf5\") in filelist:\n",
        "    print(model_name+\".hdf5 파일이 존재합니다. 가중치를 불러옵니다.\")\n",
        "\n",
        "    cnn = Sequential()\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "    cnn.add(LSTM(64))\n",
        "    cnn.add(Dropout(0.1))\n",
        "    cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "    cnn.load_weights(model_name+\".hdf5\")\n",
        "else:\n",
        "    # 새로운 모델을 학습하려는 경우\n",
        "    print(model_name+\".hdf5 파일이 존재하지 않습니다. 새로운 모델을 학습합니다.\")\n",
        "\n",
        "\n",
        "    ############################################# 모델학습 #############################################\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    lstm_output_size = 64\n",
        "\n",
        "    # 모델 학습 시작\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    cnn = Sequential()\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "    cnn.add(LSTM(lstm_output_size))\n",
        "    cnn.add(Dropout(0.1))\n",
        "    cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "    # define optimizer and objective, compile cnn\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "    # train\n",
        "    checkpointer = callbacks.ModelCheckpoint(filepath='checkpoint_2-{epoch:02d}.hdf5', verbose=1, save_best_only=True, monitor='val_acc',mode='max') #모델 성능에 향상이 있을 때마다 모델 기록\n",
        "    csv_logger = CSVLogger(os.getcwd()+'/cnntrainanalysis.csv',separator=',', append=False) #log 기록\n",
        "    history = cnn.fit(X_train, y_train, epochs=10,validation_data=(X_valid, y_valid),callbacks=[checkpointer,csv_logger],class_weight=class_weight) # class_weight=\"balanced\"는 데이터 불균형 해소를 위한 코드\n",
        "    cnn.save(\"/content/gdrive/MyDrive/Colab_Notebooks/\"+model_name+\".hdf5\") #학습이 완료된 모델 저장\n",
        "\n",
        "\n",
        "    print('\\nAccuracy: {:.4f}'.format(cnn.evaluate(X_valid, y_valid)[1])) #validation set으로 예측 성능 평가\n",
        "\n",
        "    \n",
        "    #loss graph\n",
        "\n",
        "    y_vloss = history.history['val_loss']\n",
        "    y_loss = history.history['loss']\n",
        "\n",
        "    x_len = np.arange(len(y_loss))\n",
        "    plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "    plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid()\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "########################################### 모델 성능 평가(Evaluation) #####################################\n",
        "\n",
        "#Normalize\n",
        "scaler = Normalizer().fit(x_test)\n",
        "testX = scaler.transform(x_test)\n",
        "\n",
        "y_test = np.array(testY)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_test = np.reshape(testX, (testX.shape[0],testX.shape[1],1))\n",
        "\n",
        "\n",
        "# Test 결과\n",
        "\n",
        "# define optimizer and objective, compile cnn\n",
        "opt = Adam(learning_rate=0.001)\n",
        "cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "#y_pred = cnn.predict_classes(X_test) #학습된 모델로 예측한 y값\n",
        "y_pred=cnn.predict(X_test) \n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "\n",
        "#np.savetxt('expected.txt', y_test, fmt='%01d')\n",
        "#np.savetxt('predicted.txt', y_pred, fmt='%01d')\n",
        "\n",
        "loss, accuracy = cnn.evaluate(X_test, y_test) #정답 set과 모델이 예측한 값을 비교하여 성능 측정\n",
        "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
        "print()\n",
        "print(metrics.classification_report(y_test, y_pred, digits=5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-2. SMOTE(Over sampling)"
      ],
      "metadata": {
        "id": "Q_G0f1OAMZax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=10)\n",
        "X_train_over,y_train_over = smote.fit_resample(trainX, y_train)\n",
        "X_train_under = np.reshape(X_train_under, (X_train_under.shape[0],X_train_under.shape[1],1))\n",
        "\n",
        "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', X_train.shape, y_train.shape)\n",
        "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n",
        "print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())"
      ],
      "metadata": {
        "id": "cPsg9XFty1OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "count_classes = pd.value_counts(y_train_over, sort = True,normalize=True).sort_index()\n",
        "print(count_classes*100)\n",
        "# 클래스별 데이터 분포 확인\n",
        "count_classes.plot(kind = 'bar')\n",
        "plt.title(\"class histogram\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "metadata": {
        "id": "uV8WLTRUSLpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미 존재하는 모델(model_name)을 불러오는 것인지 새로 학습하는 것인지\n",
        "#\n",
        "#\n",
        "model_name = 'CNN_LSTM_SMOTE'\n",
        "filelist = os.listdir(os.getcwd())\n",
        "\n",
        "\n",
        "# 불러오는 경우\n",
        "if (model_name+\".hdf5\") in filelist:\n",
        "    print(model_name+\".hdf5 파일이 존재합니다. 가중치를 불러옵니다.\")\n",
        "\n",
        "    cnn = Sequential()\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "    cnn.add(LSTM(64))\n",
        "    cnn.add(Dropout(0.1))\n",
        "    cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "    cnn.load_weights(model_name+\".hdf5\")\n",
        "else:\n",
        "    # 새로운 모델을 학습하려는 경우\n",
        "    print(model_name+\".hdf5 파일이 존재하지 않습니다. 새로운 모델을 학습합니다.\")\n",
        "\n",
        "\n",
        "    ############################################# 모델학습 #############################################\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    lstm_output_size = 64\n",
        "\n",
        "    # 모델 학습 시작\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    cnn = Sequential()\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "    cnn.add(LSTM(lstm_output_size))\n",
        "    cnn.add(Dropout(0.1))\n",
        "    cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "    # define optimizer and objective, compile cnn\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "    # train\n",
        "    checkpointer = callbacks.ModelCheckpoint(filepath='checkpoint_2-{epoch:02d}.hdf5', verbose=1, save_best_only=True, monitor='val_acc',mode='max') #모델 성능에 향상이 있을 때마다 모델 기록\n",
        "    csv_logger = CSVLogger(os.getcwd()+'/cnntrainanalysis.csv',separator=',', append=False) #log 기록\n",
        "    history = cnn.fit(X_train_over, y_train_over, epochs=10,validation_data=(X_valid, y_valid),callbacks=[checkpointer,csv_logger])\n",
        "    cnn.save(\"/content/gdrive/MyDrive/Colab_Notebooks/\"+model_name+\".hdf5\") #학습이 완료된 모델 저장\n",
        "\n",
        "\n",
        "    print('\\nAccuracy: {:.4f}'.format(cnn.evaluate(X_valid, y_valid)[1])) #validation set으로 예측 성능 평가\n",
        "\n",
        "    \n",
        "    #loss graph\n",
        "\n",
        "    y_vloss = history.history['val_loss']\n",
        "    y_loss = history.history['loss']\n",
        "\n",
        "    x_len = np.arange(len(y_loss))\n",
        "    plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "    plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid()\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "########################################### 모델 성능 평가(Evaluation) #####################################\n",
        "\n",
        "#Normalize\n",
        "scaler = Normalizer().fit(x_test)\n",
        "testX = scaler.transform(x_test)\n",
        "\n",
        "y_test = np.array(testY)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_test = np.reshape(testX, (testX.shape[0],testX.shape[1],1))\n",
        "\n",
        "\n",
        "# Test 결과\n",
        "\n",
        "# define optimizer and objective, compile cnn\n",
        "opt = Adam(learning_rate=0.001)\n",
        "cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "#y_pred = cnn.predict_classes(X_test) #학습된 모델로 예측한 y값\n",
        "y_pred=cnn.predict(X_test) \n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "\n",
        "#np.savetxt('expected.txt', y_test, fmt='%01d')\n",
        "#np.savetxt('predicted.txt', y_pred, fmt='%01d')\n",
        "\n",
        "loss, accuracy = cnn.evaluate(X_test, y_test) #정답 set과 모델이 예측한 값을 비교하여 성능 측정\n",
        "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
        "print()\n",
        "print(metrics.classification_report(y_test, y_pred, digits=5))"
      ],
      "metadata": {
        "id": "a28-BGqTqJZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-3. Edited Nearest Neighbours (Under sampling)"
      ],
      "metadata": {
        "id": "mlJvADkGMc_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENN\n",
        "from imblearn.under_sampling import TomekLinks,EditedNearestNeighbours\n",
        "#X_train_under, y_train_under = TomekLinks().fit_resample(trainX, y_train)\n",
        "X_train_under, y_train_under = EditedNearestNeighbours(kind_sel=\"all\", n_neighbors=5).fit_resample(trainX, y_train)\n",
        "\n",
        "X_train_under = np.reshape(X_train_under, (X_train_under.shape[0],X_train_under.shape[1],1))"
      ],
      "metadata": {
        "id": "ZHFXGtMoNwRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "count_classes = pd.value_counts(y_train_under, sort = True,normalize=True).sort_index()\n",
        "print(count_classes*100)\n",
        "# 클래스별 데이터 분포 확인\n",
        "count_classes.plot(kind = 'bar')\n",
        "plt.title(\"class histogram\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "metadata": {
        "id": "XNn6IulvX_Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미 존재하는 모델(model_name)을 불러오는 것인지 새로 학습하는 것인지\n",
        "#\n",
        "#\n",
        "model_name = 'CNN_LSTM_ENN'\n",
        "filelist = os.listdir(os.getcwd())\n",
        "\n",
        "\n",
        "# 불러오는 경우\n",
        "if (model_name+\".hdf5\") in filelist:\n",
        "    print(model_name+\".hdf5 파일이 존재합니다. 가중치를 불러옵니다.\")\n",
        "\n",
        "    cnn = Sequential()\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "    cnn.add(LSTM(64))\n",
        "    cnn.add(Dropout(0.1))\n",
        "    cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "    cnn.load_weights(model_name+\".hdf5\")\n",
        "else:\n",
        "    # 새로운 모델을 학습하려는 경우\n",
        "    print(model_name+\".hdf5 파일이 존재하지 않습니다. 새로운 모델을 학습합니다.\")\n",
        "\n",
        "\n",
        "    ############################################# 모델학습 #############################################\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    lstm_output_size = 64\n",
        "\n",
        "    # 모델 학습 시작\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    cnn = Sequential()\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "    cnn.add(LSTM(lstm_output_size))\n",
        "    cnn.add(Dropout(0.1))\n",
        "    cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "    # define optimizer and objective, compile cnn\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "    # train\n",
        "    checkpointer = callbacks.ModelCheckpoint(filepath='checkpoint_2-{epoch:02d}.hdf5', verbose=1, save_best_only=True, monitor='val_acc',mode='max') #모델 성능에 향상이 있을 때마다 모델 기록\n",
        "    csv_logger = CSVLogger(os.getcwd()+'/cnntrainanalysis.csv',separator=',', append=False) #log 기록\n",
        "    history = cnn.fit(X_train_under, y_train_under, epochs=10,validation_data=(X_valid, y_valid),callbacks=[checkpointer,csv_logger])\n",
        "    cnn.save(\"/content/gdrive/MyDrive/Colab_Notebooks/\"+model_name+\".hdf5\") #학습이 완료된 모델 저장\n",
        "\n",
        "\n",
        "    print('\\nAccuracy: {:.4f}'.format(cnn.evaluate(X_valid, y_valid)[1])) #validation set으로 예측 성능 평가\n",
        "\n",
        "    \n",
        "    #loss graph\n",
        "\n",
        "    y_vloss = history.history['val_loss']\n",
        "    y_loss = history.history['loss']\n",
        "\n",
        "    x_len = np.arange(len(y_loss))\n",
        "    plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "    plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid()\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "########################################### 모델 성능 평가(Evaluation) #####################################\n",
        "\n",
        "#Normalize\n",
        "scaler = Normalizer().fit(x_test)\n",
        "testX = scaler.transform(x_test)\n",
        "\n",
        "y_test = np.array(testY)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_test = np.reshape(testX, (testX.shape[0],testX.shape[1],1))\n",
        "\n",
        "\n",
        "# Test 결과\n",
        "\n",
        "# define optimizer and objective, compile cnn\n",
        "opt = Adam(learning_rate=0.001)\n",
        "cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "#y_pred = cnn.predict_classes(X_test) #학습된 모델로 예측한 y값\n",
        "y_pred=cnn.predict(X_test) \n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "\n",
        "#np.savetxt('expected.txt', y_test, fmt='%01d')\n",
        "#np.savetxt('predicted.txt', y_pred, fmt='%01d')\n",
        "\n",
        "loss, accuracy = cnn.evaluate(X_test, y_test) #정답 set과 모델이 예측한 값을 비교하여 성능 측정\n",
        "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
        "print()\n",
        "print(metrics.classification_report(y_test, y_pred, digits=5))"
      ],
      "metadata": {
        "id": "gPe9rbaKqS6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KSxvl60nNwbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-4. SMOTE+Tomek"
      ],
      "metadata": {
        "id": "OtRy5vBhMiUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import SMOTETomek, SMOTEENN\n",
        "#X_train_ST, y_train_ST = SMOTETomek().fit_resample(trainX, y_train)\n",
        "X_train_ST, y_train_ST = SMOTEENN().fit_resample(trainX, y_train)\n",
        "\n",
        "\n",
        "X_train_ST = np.reshape(X_train_ST, (X_train_ST.shape[0],X_train_ST.shape[1],1))"
      ],
      "metadata": {
        "id": "HqTYy2861suE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "count_classes = pd.value_counts(y_train_ST, sort = True,normalize=True).sort_index()\n",
        "print(count_classes*100)\n",
        "# 클래스별 데이터 분포 확인\n",
        "count_classes.plot(kind = 'bar')\n",
        "plt.title(\"class histogram\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "metadata": {
        "id": "c4qxmHKPp3k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미 존재하는 모델(model_name)을 불러오는 것인지 새로 학습하는 것인지\n",
        "#\n",
        "#\n",
        "model_name = 'CNN_LSTM_SMOTEENN'\n",
        "filelist = os.listdir(os.getcwd())\n",
        "\n",
        "\n",
        "# 불러오는 경우\n",
        "if (model_name+\".hdf5\") in filelist:\n",
        "    print(model_name+\".hdf5 파일이 존재합니다. 가중치를 불러옵니다.\")\n",
        "\n",
        "    cnn = Sequential()\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "    cnn.add(LSTM(64))\n",
        "    cnn.add(Dropout(0.1))\n",
        "    cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "    cnn.load_weights(model_name+\".hdf5\")\n",
        "else:\n",
        "    # 새로운 모델을 학습하려는 경우\n",
        "    print(model_name+\".hdf5 파일이 존재하지 않습니다. 새로운 모델을 학습합니다.\")\n",
        "\n",
        "\n",
        "    ############################################# 모델학습 #############################################\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    lstm_output_size = 64\n",
        "\n",
        "    # 모델 학습 시작\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    cnn = Sequential()\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(len(x.columns), 1)))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
        "    cnn.add(LSTM(lstm_output_size))\n",
        "    cnn.add(Dropout(0.1))\n",
        "    cnn.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "    # define optimizer and objective, compile cnn\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "    # train\n",
        "    checkpointer = callbacks.ModelCheckpoint(filepath='checkpoint_2-{epoch:02d}.hdf5', verbose=1, save_best_only=True, monitor='val_acc',mode='max') #모델 성능에 향상이 있을 때마다 모델 기록\n",
        "    csv_logger = CSVLogger(os.getcwd()+'/cnntrainanalysis.csv',separator=',', append=False) #log 기록\n",
        "    history = cnn.fit(X_train_ST, y_train_ST, epochs=10,validation_data=(X_valid, y_valid),callbacks=[checkpointer,csv_logger])\n",
        "    cnn.save(\"/content/gdrive/MyDrive/Colab_Notebooks/\"+model_name+\".hdf5\") #학습이 완료된 모델 저장\n",
        "\n",
        "\n",
        "    print('\\nAccuracy: {:.4f}'.format(cnn.evaluate(X_valid, y_valid)[1])) #validation set으로 예측 성능 평가\n",
        "\n",
        "    \n",
        "    #loss graph\n",
        "\n",
        "    y_vloss = history.history['val_loss']\n",
        "    y_loss = history.history['loss']\n",
        "\n",
        "    x_len = np.arange(len(y_loss))\n",
        "    plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "    plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid()\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "########################################### 모델 성능 평가(Evaluation) #####################################\n",
        "\n",
        "#Normalize\n",
        "scaler = Normalizer().fit(x_test)\n",
        "testX = scaler.transform(x_test)\n",
        "\n",
        "y_test = np.array(testY)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_test = np.reshape(testX, (testX.shape[0],testX.shape[1],1))\n",
        "\n",
        "\n",
        "# Test 결과\n",
        "\n",
        "# define optimizer and objective, compile cnn\n",
        "opt = Adam(learning_rate=0.001)\n",
        "cnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "#y_pred = cnn.predict_classes(X_test) #학습된 모델로 예측한 y값\n",
        "y_pred=cnn.predict(X_test) \n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "\n",
        "#np.savetxt('expected.txt', y_test, fmt='%01d')\n",
        "#np.savetxt('predicted.txt', y_pred, fmt='%01d')\n",
        "\n",
        "loss, accuracy = cnn.evaluate(X_test, y_test) #정답 set과 모델이 예측한 값을 비교하여 성능 측정\n",
        "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
        "print()\n",
        "print(metrics.classification_report(y_test, y_pred, digits=5))"
      ],
      "metadata": {
        "id": "3tMMk9plp3qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmeh7_l1dCWr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature_selection\n",
        "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif, chi2, mutual_info_classif\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "x = x.dropna(axis=1)\n",
        "\n",
        "estimator = ExtraTreesClassifier(n_estimators=50).fit(x,y)\n",
        "selector = SelectFromModel(estimator, prefit=True, max_features=K)\n",
        "select_column = x.columns[selector.get_support()]\n",
        "#selectK = SelectKBest(score_func=f_classif, k=K)\n",
        "#selectK.fit_transform(x, y)\n",
        "#select_column = x.columns[selectK.get_support()] #select_column은 뽑힌 k개의 열\n",
        "x = x[select_column]\n",
        "print('selectKbest 모듈에 의해 선택된 feature는 다음과 같습니다.: '+str(list(select_column)))"
      ],
      "metadata": {
        "id": "hYT4B9Tq1s2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xIBfDjuzrIoW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AI_teamproject_developed.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}